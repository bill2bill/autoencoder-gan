{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting FFHQ images to latent space Z\n",
    "\n",
    "From:\n",
    "\n",
    "- https://github.com/CompVis/latent-diffusion#pretrained-autoencoding-models\n",
    "- https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff324c0dab0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "import wget\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.utils as vutils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "from ldm.models.autoencoder import AutoencoderKL\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 6\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 300\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 128\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 128\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 20\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0001\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "IMAGE_DIR = \"/data/imagefolder/ffhq\"\n",
    "OUTPUT_DIR = \"/data/imagefolder/latent/klf4\"\n",
    "IMAGE_SIZE = 256\n",
    "WORKERS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def download_pre_trained_ae(url, output_dir):\n",
    "    if os.path.exists(output_dir):\n",
    "        print(\"Used cache\")\n",
    "    else:\n",
    "        filename = wget.download(url)\n",
    "\n",
    "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall(output_dir)\n",
    "\n",
    "        if os.path.exists(filename):\n",
    "            os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used cache\n"
     ]
    }
   ],
   "source": [
    "download_pre_trained_ae(\"https://ommer-lab.com/files/latent-diffusion/kl-f4.zip\", './klf4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 3, 64, 64) = 12288 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ddconfig = {\n",
    "    \"double_z\": True,\n",
    "    \"z_channels\": 3,\n",
    "    \"resolution\": 256,\n",
    "    \"in_channels\": 3,\n",
    "    \"out_ch\": 3,\n",
    "    \"ch\": 128,\n",
    "    \"ch_mult\": [1,2,4],\n",
    "    \"num_res_blocks\": 2,\n",
    "    \"attn_resolutions\": [],\n",
    "    \"dropout\": 0.0\n",
    "}\n",
    "lossconfig = {\n",
    "      \"target\": \"ldm.modules.losses.LPIPSWithDiscriminator\",\n",
    "      \"params\": {\n",
    "        \"disc_start\": 50001,\n",
    "        \"kl_weight\": 1.0e-06,\n",
    "        \"disc_weight\": 0.5\n",
    "      }\n",
    "}\n",
    "embed_dim = 3\n",
    "\n",
    "pl_sd = torch.load(\"klf4/model.ckpt\", map_location=\"cpu\")\n",
    "\n",
    "model = AutoencoderKL(ddconfig, lossconfig, embed_dim)\n",
    "\n",
    "model.load_state_dict(pl_sd[\"state_dict\"] ,strict=False)\n",
    "# model.cuda()\n",
    "model.to('cuda:0')\n",
    "# model.eval()\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "device = model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Generator Code\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d(300, 1024, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): ConvTranspose2d(128, 6, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (13): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create the generator\n",
    "netG = Generator().to(device)\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.02.\n",
    "netG.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(6, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (8): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (11): Conv2d(1024, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (12): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create the Discriminator\n",
    "netD = Discriminator().to(device)\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize BCELoss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Create batch of latent vectors that we will use to visualize\n",
    "#  the progression of the generator\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 0.8\n",
    "fake_label = 0.2\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# dataset = None\n",
    "\n",
    "# for file in glob.glob(f\"{OUTPUT_DIR}/*\"):\n",
    "#     if dataset is None:\n",
    "#         dataset = np.load(file)\n",
    "#     else:\n",
    "#         dataset = np.concatenate([dataset, np.load(file)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# np.load(f\"{OUTPUT_DIR}/latent_klf4_546.npy\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# class ImageDataset(Dataset):\n",
    "#   def __init__(self,csv,img_folder,transform):\n",
    "#     self.csv=csv\n",
    "#     self.transform=transform\n",
    "#     self.img_folder=img_folder\n",
    "     \n",
    "#     self.image_names=self.csv[:]['Id']\n",
    "#     self.labels=np.array(self.csv.drop(['Id', 'Genre'], axis=1))\n",
    "   \n",
    "# #The __len__ function returns the number of samples in our dataset.\n",
    "#   def __len__(self):\n",
    "#     return len(self.image_names)\n",
    " \n",
    "#   def __getitem__(self,index):\n",
    "     \n",
    "#     image=cv2.imread(self.img_folder+self.image_names.iloc[index]+'.jpg')\n",
    "#     image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    " \n",
    "#     image=self.transform(image)\n",
    "#     targets=self.labels[index]\n",
    "     \n",
    "#     sample = {'image': image,'labels':targets}\n",
    " \n",
    "#     return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def npy_loader(path):\n",
    "    return torch.from_numpy(np.load(path))\n",
    "\n",
    "dataset = dset.DatasetFolder(\n",
    "    root=\"/data/imagefolder/latent\",\n",
    "    loader=npy_loader,\n",
    "    extensions='.npy',\n",
    "    transform=transforms.Compose([\n",
    "        # transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0,0,0,0,0,0], std=[80, 80, 80, 80, 80, 80]),\n",
    "    ])\n",
    ")\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6, 64, 64])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloader))[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n",
      "[0/20][0/546]\tLoss_D: 2.0458\tLoss_G: 8.0103\tD(x): 0.7104\tD(G(z)): 0.6745 / 0.0001\n",
      "[0/20][50/546]\tLoss_D: 5.7049\tLoss_G: 12.9208\tD(x): 0.8369\tD(G(z)): 0.9965 / 0.0000\n",
      "[0/20][100/546]\tLoss_D: 4.2841\tLoss_G: 17.3127\tD(x): 0.5736\tD(G(z)): 0.0000 / 0.0000\n",
      "[0/20][150/546]\tLoss_D: 1.2515\tLoss_G: 0.6126\tD(x): 0.8658\tD(G(z)): 0.1049 / 0.9296\n",
      "[0/20][200/546]\tLoss_D: 2.2131\tLoss_G: 3.4623\tD(x): 0.6597\tD(G(z)): 0.0006 / 0.0162\n",
      "[0/20][250/546]\tLoss_D: 2.4122\tLoss_G: 14.1127\tD(x): 0.7717\tD(G(z)): 0.8554 / 0.0000\n",
      "[0/20][300/546]\tLoss_D: 1.6050\tLoss_G: 4.0998\tD(x): 0.6911\tD(G(z)): 0.0121 / 0.0068\n",
      "[0/20][350/546]\tLoss_D: 1.2962\tLoss_G: 2.0815\tD(x): 0.6993\tD(G(z)): 0.4028 / 0.0884\n",
      "[0/20][400/546]\tLoss_D: 1.2212\tLoss_G: 1.3305\tD(x): 0.6306\tD(G(z)): 0.3002 / 0.2122\n",
      "[0/20][450/546]\tLoss_D: 1.3583\tLoss_G: 1.4301\tD(x): 0.6720\tD(G(z)): 0.5127 / 0.1998\n",
      "[0/20][500/546]\tLoss_D: 1.2159\tLoss_G: 1.1656\tD(x): 0.6178\tD(G(z)): 0.3173 / 0.2728\n",
      "[1/20][0/546]\tLoss_D: 1.1984\tLoss_G: 1.3367\tD(x): 0.6840\tD(G(z)): 0.3846 / 0.2155\n",
      "[1/20][50/546]\tLoss_D: 1.1647\tLoss_G: 1.2717\tD(x): 0.6635\tD(G(z)): 0.3240 / 0.2305\n",
      "[1/20][100/546]\tLoss_D: 1.2492\tLoss_G: 1.6782\tD(x): 0.7270\tD(G(z)): 0.4763 / 0.1380\n",
      "[1/20][150/546]\tLoss_D: 1.1919\tLoss_G: 1.5229\tD(x): 0.6956\tD(G(z)): 0.3783 / 0.1681\n",
      "[1/20][200/546]\tLoss_D: 1.1897\tLoss_G: 1.2612\tD(x): 0.6707\tD(G(z)): 0.3650 / 0.2418\n",
      "[1/20][250/546]\tLoss_D: 1.2558\tLoss_G: 1.4043\tD(x): 0.7168\tD(G(z)): 0.4682 / 0.2006\n",
      "[1/20][300/546]\tLoss_D: 1.2936\tLoss_G: 0.8606\tD(x): 0.5018\tD(G(z)): 0.2452 / 0.4065\n",
      "[1/20][350/546]\tLoss_D: 1.2310\tLoss_G: 1.1017\tD(x): 0.5875\tD(G(z)): 0.3606 / 0.2905\n",
      "[1/20][400/546]\tLoss_D: 1.3145\tLoss_G: 1.0624\tD(x): 0.5032\tD(G(z)): 0.2769 / 0.3043\n",
      "[1/20][450/546]\tLoss_D: 1.2603\tLoss_G: 0.9495\tD(x): 0.5353\tD(G(z)): 0.3095 / 0.3629\n",
      "[1/20][500/546]\tLoss_D: 1.1685\tLoss_G: 1.2021\tD(x): 0.6353\tD(G(z)): 0.3285 / 0.2559\n",
      "[2/20][0/546]\tLoss_D: 1.3479\tLoss_G: 1.5953\tD(x): 0.7031\tD(G(z)): 0.5174 / 0.1587\n",
      "[2/20][50/546]\tLoss_D: 1.1937\tLoss_G: 1.5141\tD(x): 0.7102\tD(G(z)): 0.4119 / 0.1706\n",
      "[2/20][100/546]\tLoss_D: 1.3040\tLoss_G: 1.4876\tD(x): 0.7357\tD(G(z)): 0.5143 / 0.1891\n",
      "[2/20][150/546]\tLoss_D: 1.1619\tLoss_G: 1.2482\tD(x): 0.6248\tD(G(z)): 0.2994 / 0.2428\n",
      "[2/20][200/546]\tLoss_D: 1.2214\tLoss_G: 1.6628\tD(x): 0.7249\tD(G(z)): 0.4546 / 0.1425\n",
      "[2/20][250/546]\tLoss_D: 1.2565\tLoss_G: 1.8095\tD(x): 0.7940\tD(G(z)): 0.4969 / 0.1227\n",
      "[2/20][300/546]\tLoss_D: 1.1467\tLoss_G: 1.0892\tD(x): 0.6281\tD(G(z)): 0.2831 / 0.2993\n",
      "[2/20][350/546]\tLoss_D: 1.2233\tLoss_G: 0.9292\tD(x): 0.5529\tD(G(z)): 0.2633 / 0.3787\n",
      "[2/20][400/546]\tLoss_D: 1.1057\tLoss_G: 1.6143\tD(x): 0.7515\tD(G(z)): 0.3474 / 0.1495\n",
      "[2/20][450/546]\tLoss_D: 1.1736\tLoss_G: 1.0932\tD(x): 0.6543\tD(G(z)): 0.3388 / 0.2969\n",
      "[2/20][500/546]\tLoss_D: 1.1503\tLoss_G: 1.0133\tD(x): 0.6427\tD(G(z)): 0.3192 / 0.3231\n",
      "[3/20][0/546]\tLoss_D: 1.1192\tLoss_G: 1.0797\tD(x): 0.6385\tD(G(z)): 0.2474 / 0.2977\n",
      "[3/20][50/546]\tLoss_D: 1.1992\tLoss_G: 1.1044\tD(x): 0.5802\tD(G(z)): 0.1922 / 0.2907\n",
      "[3/20][100/546]\tLoss_D: 1.1037\tLoss_G: 1.4851\tD(x): 0.7324\tD(G(z)): 0.2903 / 0.1755\n",
      "[3/20][150/546]\tLoss_D: 1.2336\tLoss_G: 1.9169\tD(x): 0.8094\tD(G(z)): 0.4727 / 0.1024\n",
      "[3/20][200/546]\tLoss_D: 1.1723\tLoss_G: 1.5091\tD(x): 0.7272\tD(G(z)): 0.3922 / 0.1748\n",
      "[3/20][250/546]\tLoss_D: 1.2379\tLoss_G: 1.6487\tD(x): 0.7888\tD(G(z)): 0.4703 / 0.1483\n",
      "[3/20][300/546]\tLoss_D: 1.2328\tLoss_G: 1.6997\tD(x): 0.7636\tD(G(z)): 0.4813 / 0.1363\n",
      "[3/20][350/546]\tLoss_D: 1.1572\tLoss_G: 1.4706\tD(x): 0.7001\tD(G(z)): 0.3347 / 0.1850\n",
      "[3/20][400/546]\tLoss_D: 1.1729\tLoss_G: 1.1843\tD(x): 0.5998\tD(G(z)): 0.2405 / 0.2705\n",
      "[3/20][450/546]\tLoss_D: 1.2680\tLoss_G: 1.5209\tD(x): 0.7001\tD(G(z)): 0.4572 / 0.1771\n",
      "[3/20][500/546]\tLoss_D: 1.1805\tLoss_G: 1.4082\tD(x): 0.7005\tD(G(z)): 0.3874 / 0.1979\n",
      "[4/20][0/546]\tLoss_D: 1.3629\tLoss_G: 0.9644\tD(x): 0.4752\tD(G(z)): 0.2283 / 0.3621\n",
      "[4/20][50/546]\tLoss_D: 1.1781\tLoss_G: 1.1374\tD(x): 0.6096\tD(G(z)): 0.2917 / 0.2790\n",
      "[4/20][100/546]\tLoss_D: 1.2264\tLoss_G: 1.7811\tD(x): 0.7312\tD(G(z)): 0.4272 / 0.1255\n",
      "[4/20][150/546]\tLoss_D: 1.4707\tLoss_G: 2.1695\tD(x): 0.8594\tD(G(z)): 0.6080 / 0.0819\n",
      "[4/20][200/546]\tLoss_D: 1.1559\tLoss_G: 1.2678\tD(x): 0.6405\tD(G(z)): 0.3190 / 0.2350\n",
      "[4/20][250/546]\tLoss_D: 1.1986\tLoss_G: 1.2440\tD(x): 0.6628\tD(G(z)): 0.3989 / 0.2389\n",
      "[4/20][300/546]\tLoss_D: 1.2040\tLoss_G: 1.1591\tD(x): 0.6162\tD(G(z)): 0.3543 / 0.2682\n",
      "[4/20][350/546]\tLoss_D: 1.2250\tLoss_G: 1.0189\tD(x): 0.5623\tD(G(z)): 0.2580 / 0.3296\n",
      "[4/20][400/546]\tLoss_D: 1.1829\tLoss_G: 1.2809\tD(x): 0.6112\tD(G(z)): 0.3008 / 0.2380\n",
      "[4/20][450/546]\tLoss_D: 1.2570\tLoss_G: 1.8771\tD(x): 0.7631\tD(G(z)): 0.4912 / 0.1080\n",
      "[4/20][500/546]\tLoss_D: 1.2871\tLoss_G: 2.0126\tD(x): 0.7926\tD(G(z)): 0.5237 / 0.0928\n",
      "[5/20][0/546]\tLoss_D: 1.2296\tLoss_G: 2.1043\tD(x): 0.7510\tD(G(z)): 0.4574 / 0.0879\n",
      "[5/20][50/546]\tLoss_D: 1.2716\tLoss_G: 1.9175\tD(x): 0.7556\tD(G(z)): 0.4939 / 0.1048\n",
      "[5/20][100/546]\tLoss_D: 1.1554\tLoss_G: 1.8665\tD(x): 0.7578\tD(G(z)): 0.3973 / 0.1093\n",
      "[5/20][150/546]\tLoss_D: 1.2063\tLoss_G: 1.4176\tD(x): 0.6373\tD(G(z)): 0.3635 / 0.1904\n",
      "[5/20][200/546]\tLoss_D: 1.2341\tLoss_G: 2.0495\tD(x): 0.7510\tD(G(z)): 0.4750 / 0.0859\n",
      "[5/20][250/546]\tLoss_D: 1.1600\tLoss_G: 1.0613\tD(x): 0.5917\tD(G(z)): 0.2524 / 0.3057\n",
      "[5/20][300/546]\tLoss_D: 1.1931\tLoss_G: 1.8746\tD(x): 0.7340\tD(G(z)): 0.4386 / 0.1062\n",
      "[5/20][350/546]\tLoss_D: 1.2287\tLoss_G: 0.8759\tD(x): 0.5387\tD(G(z)): 0.2028 / 0.4018\n",
      "[5/20][400/546]\tLoss_D: 1.2529\tLoss_G: 1.0711\tD(x): 0.5264\tD(G(z)): 0.1881 / 0.3087\n",
      "[5/20][450/546]\tLoss_D: 1.1696\tLoss_G: 1.3933\tD(x): 0.6422\tD(G(z)): 0.3264 / 0.2003\n",
      "[5/20][500/546]\tLoss_D: 1.3359\tLoss_G: 1.8703\tD(x): 0.8149\tD(G(z)): 0.5472 / 0.1128\n",
      "[6/20][0/546]\tLoss_D: 1.3119\tLoss_G: 0.9708\tD(x): 0.4822\tD(G(z)): 0.1333 / 0.3472\n",
      "[6/20][50/546]\tLoss_D: 1.3122\tLoss_G: 1.0828\tD(x): 0.4870\tD(G(z)): 0.1276 / 0.3030\n",
      "[6/20][100/546]\tLoss_D: 1.2853\tLoss_G: 2.2622\tD(x): 0.7849\tD(G(z)): 0.5170 / 0.0667\n",
      "[6/20][150/546]\tLoss_D: 1.1760\tLoss_G: 1.4746\tD(x): 0.6403\tD(G(z)): 0.2894 / 0.1860\n",
      "[6/20][200/546]\tLoss_D: 1.1313\tLoss_G: 1.7171\tD(x): 0.7502\tD(G(z)): 0.3627 / 0.1333\n",
      "[6/20][250/546]\tLoss_D: 1.1746\tLoss_G: 1.7394\tD(x): 0.6748\tD(G(z)): 0.3920 / 0.1306\n",
      "[6/20][300/546]\tLoss_D: 1.2692\tLoss_G: 0.8719\tD(x): 0.4907\tD(G(z)): 0.1925 / 0.3986\n",
      "[6/20][350/546]\tLoss_D: 1.1204\tLoss_G: 1.3111\tD(x): 0.6774\tD(G(z)): 0.3152 / 0.2197\n",
      "[6/20][400/546]\tLoss_D: 1.1552\tLoss_G: 1.2131\tD(x): 0.6061\tD(G(z)): 0.2005 / 0.2517\n",
      "[6/20][450/546]\tLoss_D: 1.2286\tLoss_G: 2.0909\tD(x): 0.8360\tD(G(z)): 0.4784 / 0.0840\n",
      "[6/20][500/546]\tLoss_D: 1.4045\tLoss_G: 2.6939\tD(x): 0.8730\tD(G(z)): 0.5866 / 0.0408\n",
      "[7/20][0/546]\tLoss_D: 1.1833\tLoss_G: 1.1654\tD(x): 0.5786\tD(G(z)): 0.1365 / 0.2670\n",
      "[7/20][50/546]\tLoss_D: 1.8013\tLoss_G: 0.8956\tD(x): 0.3193\tD(G(z)): 0.0388 / 0.3990\n",
      "[7/20][100/546]\tLoss_D: 1.1159\tLoss_G: 1.2483\tD(x): 0.6582\tD(G(z)): 0.2586 / 0.2376\n",
      "[7/20][150/546]\tLoss_D: 1.2119\tLoss_G: 2.3595\tD(x): 0.8077\tD(G(z)): 0.4571 / 0.0581\n",
      "[7/20][200/546]\tLoss_D: 1.1204\tLoss_G: 1.8374\tD(x): 0.7485\tD(G(z)): 0.3566 / 0.1134\n",
      "[7/20][250/546]\tLoss_D: 1.2029\tLoss_G: 0.9788\tD(x): 0.5487\tD(G(z)): 0.1616 / 0.3417\n",
      "[7/20][300/546]\tLoss_D: 1.3844\tLoss_G: 1.0171\tD(x): 0.4405\tD(G(z)): 0.1408 / 0.3364\n",
      "[7/20][350/546]\tLoss_D: 1.1270\tLoss_G: 1.1437\tD(x): 0.6166\tD(G(z)): 0.2417 / 0.2717\n",
      "[7/20][400/546]\tLoss_D: 1.1612\tLoss_G: 2.1780\tD(x): 0.8236\tD(G(z)): 0.4211 / 0.0737\n",
      "[7/20][450/546]\tLoss_D: 1.0901\tLoss_G: 1.6073\tD(x): 0.7138\tD(G(z)): 0.2797 / 0.1543\n",
      "[7/20][500/546]\tLoss_D: 1.3234\tLoss_G: 0.7677\tD(x): 0.4841\tD(G(z)): 0.1072 / 0.4656\n",
      "[8/20][0/546]\tLoss_D: 1.2073\tLoss_G: 1.0215\tD(x): 0.5696\tD(G(z)): 0.1163 / 0.3267\n",
      "[8/20][50/546]\tLoss_D: 1.1000\tLoss_G: 1.5050\tD(x): 0.7042\tD(G(z)): 0.2847 / 0.1708\n",
      "[8/20][100/546]\tLoss_D: 1.3629\tLoss_G: 0.8396\tD(x): 0.4674\tD(G(z)): 0.0915 / 0.4175\n",
      "[8/20][150/546]\tLoss_D: 1.0892\tLoss_G: 1.9008\tD(x): 0.7771\tD(G(z)): 0.3312 / 0.1023\n",
      "[8/20][200/546]\tLoss_D: 1.1564\tLoss_G: 2.0123\tD(x): 0.7879\tD(G(z)): 0.4257 / 0.0905\n",
      "[8/20][250/546]\tLoss_D: 1.1288\tLoss_G: 1.9543\tD(x): 0.7251\tD(G(z)): 0.3733 / 0.0964\n",
      "[8/20][300/546]\tLoss_D: 1.1366\tLoss_G: 1.0008\tD(x): 0.5982\tD(G(z)): 0.2145 / 0.3311\n",
      "[8/20][350/546]\tLoss_D: 1.2598\tLoss_G: 0.9831\tD(x): 0.5121\tD(G(z)): 0.1124 / 0.3408\n",
      "[8/20][400/546]\tLoss_D: 1.0971\tLoss_G: 1.4248\tD(x): 0.6948\tD(G(z)): 0.3049 / 0.1891\n",
      "[8/20][450/546]\tLoss_D: 1.0916\tLoss_G: 1.4128\tD(x): 0.7244\tD(G(z)): 0.3085 / 0.1950\n",
      "[8/20][500/546]\tLoss_D: 1.0869\tLoss_G: 1.2313\tD(x): 0.6848\tD(G(z)): 0.2634 / 0.2400\n",
      "[9/20][0/546]\tLoss_D: 1.4136\tLoss_G: 2.9931\tD(x): 0.8743\tD(G(z)): 0.5961 / 0.0281\n",
      "[9/20][50/546]\tLoss_D: 1.0668\tLoss_G: 1.5251\tD(x): 0.7135\tD(G(z)): 0.2464 / 0.1672\n",
      "[9/20][100/546]\tLoss_D: 1.0916\tLoss_G: 1.5245\tD(x): 0.7539\tD(G(z)): 0.3396 / 0.1662\n",
      "[9/20][150/546]\tLoss_D: 1.0806\tLoss_G: 1.3885\tD(x): 0.6741\tD(G(z)): 0.2100 / 0.1975\n",
      "[9/20][200/546]\tLoss_D: 1.1682\tLoss_G: 1.9033\tD(x): 0.8484\tD(G(z)): 0.4251 / 0.1043\n",
      "[9/20][250/546]\tLoss_D: 1.1184\tLoss_G: 1.0853\tD(x): 0.6175\tD(G(z)): 0.2172 / 0.2952\n",
      "[9/20][300/546]\tLoss_D: 1.1967\tLoss_G: 0.8653\tD(x): 0.5332\tD(G(z)): 0.1800 / 0.3947\n",
      "[9/20][350/546]\tLoss_D: 1.1841\tLoss_G: 2.2625\tD(x): 0.7674\tD(G(z)): 0.4502 / 0.0667\n",
      "[9/20][400/546]\tLoss_D: 1.1282\tLoss_G: 1.0777\tD(x): 0.6060\tD(G(z)): 0.1993 / 0.2971\n",
      "[9/20][450/546]\tLoss_D: 1.0596\tLoss_G: 1.2412\tD(x): 0.7133\tD(G(z)): 0.2265 / 0.2348\n",
      "[9/20][500/546]\tLoss_D: 1.0836\tLoss_G: 1.2429\tD(x): 0.6838\tD(G(z)): 0.2731 / 0.2350\n",
      "[10/20][0/546]\tLoss_D: 1.2899\tLoss_G: 1.9830\tD(x): 0.8655\tD(G(z)): 0.5272 / 0.0931\n",
      "[10/20][50/546]\tLoss_D: 1.1009\tLoss_G: 1.2479\tD(x): 0.6399\tD(G(z)): 0.1832 / 0.2354\n",
      "[10/20][100/546]\tLoss_D: 1.0937\tLoss_G: 1.1804\tD(x): 0.6515\tD(G(z)): 0.2365 / 0.2588\n",
      "[10/20][150/546]\tLoss_D: 1.0944\tLoss_G: 1.1500\tD(x): 0.6563\tD(G(z)): 0.2069 / 0.2661\n",
      "[10/20][200/546]\tLoss_D: 1.3649\tLoss_G: 2.5422\tD(x): 0.8847\tD(G(z)): 0.5695 / 0.0456\n",
      "[10/20][250/546]\tLoss_D: 1.0801\tLoss_G: 1.3611\tD(x): 0.6937\tD(G(z)): 0.2715 / 0.2037\n",
      "[10/20][300/546]\tLoss_D: 1.1383\tLoss_G: 1.1585\tD(x): 0.6018\tD(G(z)): 0.2403 / 0.2688\n",
      "[10/20][350/546]\tLoss_D: 1.1275\tLoss_G: 1.5755\tD(x): 0.7388\tD(G(z)): 0.3842 / 0.1549\n",
      "[10/20][400/546]\tLoss_D: 1.1074\tLoss_G: 1.2162\tD(x): 0.6407\tD(G(z)): 0.2317 / 0.2466\n",
      "[10/20][450/546]\tLoss_D: 1.0946\tLoss_G: 1.7301\tD(x): 0.7613\tD(G(z)): 0.3370 / 0.1278\n",
      "[10/20][500/546]\tLoss_D: 1.3718\tLoss_G: 0.6266\tD(x): 0.4324\tD(G(z)): 0.1058 / 0.5820\n",
      "[11/20][0/546]\tLoss_D: 1.0772\tLoss_G: 1.4607\tD(x): 0.7193\tD(G(z)): 0.2845 / 0.1800\n",
      "[11/20][50/546]\tLoss_D: 1.1296\tLoss_G: 1.0689\tD(x): 0.6064\tD(G(z)): 0.1728 / 0.2983\n",
      "[11/20][100/546]\tLoss_D: 1.0680\tLoss_G: 1.4889\tD(x): 0.7587\tD(G(z)): 0.3157 / 0.1708\n",
      "[11/20][150/546]\tLoss_D: 1.0692\tLoss_G: 1.5352\tD(x): 0.7536\tD(G(z)): 0.3051 / 0.1613\n",
      "[11/20][200/546]\tLoss_D: 1.2866\tLoss_G: 2.8067\tD(x): 0.8534\tD(G(z)): 0.5334 / 0.0331\n",
      "[11/20][250/546]\tLoss_D: 1.0969\tLoss_G: 1.1200\tD(x): 0.6427\tD(G(z)): 0.2081 / 0.2808\n",
      "[11/20][300/546]\tLoss_D: 1.0991\tLoss_G: 1.6472\tD(x): 0.7261\tD(G(z)): 0.3484 / 0.1378\n",
      "[11/20][350/546]\tLoss_D: 1.1435\tLoss_G: 1.7210\tD(x): 0.7864\tD(G(z)): 0.3970 / 0.1308\n",
      "[11/20][400/546]\tLoss_D: 1.1486\tLoss_G: 2.0643\tD(x): 0.7603\tD(G(z)): 0.4181 / 0.0827\n",
      "[11/20][450/546]\tLoss_D: 1.1311\tLoss_G: 1.1260\tD(x): 0.6168\tD(G(z)): 0.1570 / 0.2788\n",
      "[11/20][500/546]\tLoss_D: 1.0833\tLoss_G: 1.4772\tD(x): 0.7504\tD(G(z)): 0.3322 / 0.1742\n",
      "[12/20][0/546]\tLoss_D: 1.2727\tLoss_G: 1.1018\tD(x): 0.5305\tD(G(z)): 0.0877 / 0.2917\n",
      "[12/20][50/546]\tLoss_D: 1.2111\tLoss_G: 1.0936\tD(x): 0.5580\tD(G(z)): 0.1036 / 0.2882\n",
      "[12/20][100/546]\tLoss_D: 1.2439\tLoss_G: 0.7611\tD(x): 0.5003\tD(G(z)): 0.1339 / 0.4624\n",
      "[12/20][150/546]\tLoss_D: 1.1072\tLoss_G: 1.0868\tD(x): 0.6448\tD(G(z)): 0.1538 / 0.2944\n",
      "[12/20][200/546]\tLoss_D: 1.0649\tLoss_G: 1.6672\tD(x): 0.7586\tD(G(z)): 0.3117 / 0.1347\n",
      "[12/20][250/546]\tLoss_D: 1.0751\tLoss_G: 1.5065\tD(x): 0.7325\tD(G(z)): 0.3040 / 0.1674\n",
      "[12/20][300/546]\tLoss_D: 1.1138\tLoss_G: 1.2212\tD(x): 0.6455\tD(G(z)): 0.2901 / 0.2438\n",
      "[12/20][350/546]\tLoss_D: 1.1485\tLoss_G: 0.9273\tD(x): 0.5922\tD(G(z)): 0.1620 / 0.3620\n",
      "[12/20][400/546]\tLoss_D: 1.0769\tLoss_G: 1.3168\tD(x): 0.6982\tD(G(z)): 0.2849 / 0.2131\n",
      "[12/20][450/546]\tLoss_D: 1.1059\tLoss_G: 1.0548\tD(x): 0.6398\tD(G(z)): 0.1639 / 0.3027\n",
      "[12/20][500/546]\tLoss_D: 1.1229\tLoss_G: 1.1594\tD(x): 0.6065\tD(G(z)): 0.2168 / 0.2647\n",
      "[13/20][0/546]\tLoss_D: 1.3404\tLoss_G: 2.1234\tD(x): 0.8861\tD(G(z)): 0.5527 / 0.0772\n",
      "[13/20][50/546]\tLoss_D: 1.0719\tLoss_G: 1.3872\tD(x): 0.7077\tD(G(z)): 0.2705 / 0.1953\n",
      "[13/20][100/546]\tLoss_D: 1.0705\tLoss_G: 1.2797\tD(x): 0.6856\tD(G(z)): 0.2013 / 0.2253\n",
      "[13/20][150/546]\tLoss_D: 1.0596\tLoss_G: 1.2706\tD(x): 0.7259\tD(G(z)): 0.2545 / 0.2290\n",
      "[13/20][200/546]\tLoss_D: 1.1750\tLoss_G: 1.6211\tD(x): 0.8093\tD(G(z)): 0.4496 / 0.1455\n",
      "[13/20][250/546]\tLoss_D: 1.0864\tLoss_G: 1.2781\tD(x): 0.6672\tD(G(z)): 0.2389 / 0.2286\n",
      "[13/20][300/546]\tLoss_D: 1.1186\tLoss_G: 1.4618\tD(x): 0.7268\tD(G(z)): 0.3765 / 0.1760\n",
      "[13/20][350/546]\tLoss_D: 1.0781\tLoss_G: 1.2400\tD(x): 0.6819\tD(G(z)): 0.2625 / 0.2366\n",
      "[13/20][400/546]\tLoss_D: 1.0888\tLoss_G: 1.3971\tD(x): 0.7135\tD(G(z)): 0.3192 / 0.1923\n",
      "[13/20][450/546]\tLoss_D: 1.4876\tLoss_G: 0.7928\tD(x): 0.3948\tD(G(z)): 0.0659 / 0.4430\n",
      "[13/20][500/546]\tLoss_D: 1.1115\tLoss_G: 1.1432\tD(x): 0.6263\tD(G(z)): 0.2293 / 0.2702\n",
      "[14/20][0/546]\tLoss_D: 1.1068\tLoss_G: 1.7564\tD(x): 0.7597\tD(G(z)): 0.3680 / 0.1205\n",
      "[14/20][50/546]\tLoss_D: 1.0428\tLoss_G: 1.4956\tD(x): 0.7452\tD(G(z)): 0.2476 / 0.1680\n",
      "[14/20][100/546]\tLoss_D: 1.0589\tLoss_G: 1.6027\tD(x): 0.7865\tD(G(z)): 0.3140 / 0.1460\n",
      "[14/20][150/546]\tLoss_D: 1.1766\tLoss_G: 1.0622\tD(x): 0.5786\tD(G(z)): 0.1314 / 0.3051\n",
      "[14/20][200/546]\tLoss_D: 1.3343\tLoss_G: 2.3549\tD(x): 0.8875\tD(G(z)): 0.5407 / 0.0589\n",
      "[14/20][250/546]\tLoss_D: 1.1805\tLoss_G: 1.8134\tD(x): 0.8196\tD(G(z)): 0.4477 / 0.1128\n",
      "[14/20][300/546]\tLoss_D: 1.1024\tLoss_G: 1.0092\tD(x): 0.6257\tD(G(z)): 0.2068 / 0.3217\n",
      "[14/20][350/546]\tLoss_D: 1.1000\tLoss_G: 1.1913\tD(x): 0.6586\tD(G(z)): 0.2921 / 0.2505\n",
      "[14/20][400/546]\tLoss_D: 1.0837\tLoss_G: 1.3408\tD(x): 0.7131\tD(G(z)): 0.3014 / 0.2090\n",
      "[14/20][450/546]\tLoss_D: 1.3024\tLoss_G: 0.9208\tD(x): 0.4992\tD(G(z)): 0.0845 / 0.3661\n",
      "[14/20][500/546]\tLoss_D: 1.0766\tLoss_G: 1.4798\tD(x): 0.7154\tD(G(z)): 0.3057 / 0.1736\n",
      "[15/20][0/546]\tLoss_D: 1.1483\tLoss_G: 1.9598\tD(x): 0.8106\tD(G(z)): 0.4263 / 0.0941\n",
      "[15/20][50/546]\tLoss_D: 1.4093\tLoss_G: 1.9606\tD(x): 0.9021\tD(G(z)): 0.5848 / 0.0970\n",
      "[15/20][100/546]\tLoss_D: 1.1026\tLoss_G: 1.6033\tD(x): 0.8100\tD(G(z)): 0.3836 / 0.1459\n",
      "[15/20][150/546]\tLoss_D: 1.0611\tLoss_G: 1.2570\tD(x): 0.7007\tD(G(z)): 0.2226 / 0.2307\n",
      "[15/20][200/546]\tLoss_D: 1.0930\tLoss_G: 1.0829\tD(x): 0.6411\tD(G(z)): 0.1706 / 0.2913\n",
      "[15/20][250/546]\tLoss_D: 1.1396\tLoss_G: 0.9660\tD(x): 0.5974\tD(G(z)): 0.1476 / 0.3465\n",
      "[15/20][300/546]\tLoss_D: 1.0413\tLoss_G: 1.3185\tD(x): 0.7568\tD(G(z)): 0.2542 / 0.2119\n",
      "[15/20][350/546]\tLoss_D: 1.0799\tLoss_G: 0.9720\tD(x): 0.6635\tD(G(z)): 0.2352 / 0.3382\n",
      "[15/20][400/546]\tLoss_D: 1.0798\tLoss_G: 1.3061\tD(x): 0.6913\tD(G(z)): 0.2759 / 0.2158\n",
      "[15/20][450/546]\tLoss_D: 1.0700\tLoss_G: 1.3649\tD(x): 0.6856\tD(G(z)): 0.1726 / 0.2021\n",
      "[15/20][500/546]\tLoss_D: 1.0653\tLoss_G: 1.3567\tD(x): 0.7638\tD(G(z)): 0.3127 / 0.2021\n",
      "[16/20][0/546]\tLoss_D: 1.0806\tLoss_G: 1.2641\tD(x): 0.6721\tD(G(z)): 0.2560 / 0.2299\n",
      "[16/20][50/546]\tLoss_D: 1.0863\tLoss_G: 1.6225\tD(x): 0.8012\tD(G(z)): 0.3538 / 0.1439\n",
      "[16/20][100/546]\tLoss_D: 1.0649\tLoss_G: 1.1588\tD(x): 0.6862\tD(G(z)): 0.2561 / 0.2607\n",
      "[16/20][150/546]\tLoss_D: 1.1768\tLoss_G: 0.9787\tD(x): 0.5575\tD(G(z)): 0.2107 / 0.3396\n",
      "[16/20][200/546]\tLoss_D: 1.0681\tLoss_G: 1.6637\tD(x): 0.7407\tD(G(z)): 0.2975 / 0.1365\n",
      "[16/20][250/546]\tLoss_D: 1.0763\tLoss_G: 1.2699\tD(x): 0.6603\tD(G(z)): 0.2166 / 0.2267\n",
      "[16/20][300/546]\tLoss_D: 1.0618\tLoss_G: 1.2804\tD(x): 0.7130\tD(G(z)): 0.2648 / 0.2238\n",
      "[16/20][350/546]\tLoss_D: 1.3599\tLoss_G: 0.7288\tD(x): 0.4430\tD(G(z)): 0.1000 / 0.4902\n",
      "[16/20][400/546]\tLoss_D: 1.0876\tLoss_G: 1.5989\tD(x): 0.7526\tD(G(z)): 0.3421 / 0.1478\n",
      "[16/20][450/546]\tLoss_D: 1.0721\tLoss_G: 1.6330\tD(x): 0.8338\tD(G(z)): 0.3269 / 0.1412\n",
      "[16/20][500/546]\tLoss_D: 1.0497\tLoss_G: 1.3419\tD(x): 0.7036\tD(G(z)): 0.2164 / 0.2044\n",
      "[17/20][0/546]\tLoss_D: 1.0993\tLoss_G: 1.7202\tD(x): 0.7949\tD(G(z)): 0.3667 / 0.1265\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "\n",
    "# Lists to keep track of progress\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "        netD.zero_grad()\n",
    "        # Format batch\n",
    "        real_cpu = data[0][0].to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "        # Forward pass real batch through D\n",
    "        output = netD(real_cpu).view(-1)\n",
    "        # Calculate loss on all-real batch\n",
    "        errD_real = criterion(output, label)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        # Generate fake image batch with G\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        # Classify all fake batch with D\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        errD_fake = criterion(output, label)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # Compute error of D as sum over the fake and the real batches\n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        output = netD(fake).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        errG = criterion(output, label)\n",
    "        # Calculate gradients for G\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Update G\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, num_epochs, i, len(dataloader),\n",
    "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "259771fb0e24a764efce4fd955c0b099f3a7b4b1af73db6068fac1ad6a526fe6"
  },
  "kernelspec": {
   "display_name": "will py3",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
