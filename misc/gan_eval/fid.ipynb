{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FID Score Pytorch\n",
    "\n",
    "Following the tutorial:\n",
    "\n",
    "- https://machinelearningmastery.com/how-to-implement-the-frechet-inception-distance-fid-from-scratch/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Native Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from scipy import linalg\n",
    "\n",
    "from numpy.random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\willf/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\n",
    "model.eval()\n",
    "\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
    "    \"\"\"Numpy implementation of the Frechet Distance.\n",
    "    The Frechet distance between two multivariate Gaussians X_1 ~ N(mu_1, C_1)\n",
    "    and X_2 ~ N(mu_2, C_2) is\n",
    "            d^2 = ||mu_1 - mu_2||^2 + Tr(C_1 + C_2 - 2*sqrt(C_1*C_2)).\n",
    "    \"\"\"\n",
    "\n",
    "    mu1 = np.atleast_1d(mu1)\n",
    "    mu2 = np.atleast_1d(mu2)\n",
    "\n",
    "    sigma1 = np.atleast_2d(sigma1)\n",
    "    sigma2 = np.atleast_2d(sigma2)\n",
    "\n",
    "    assert mu1.shape == mu2.shape, \\\n",
    "        'Training and test mean vectors have different lengths'\n",
    "    assert sigma1.shape == sigma2.shape, \\\n",
    "        'Training and test covariances have different dimensions'\n",
    "\n",
    "    diff = mu1 - mu2\n",
    "\n",
    "    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
    "    if not np.isfinite(covmean).all():\n",
    "        msg = ('fid calculation produces singular product; '\n",
    "               'adding %s to diagonal of cov estimates') % eps\n",
    "        print(msg)\n",
    "        offset = np.eye(sigma1.shape[0]) * eps\n",
    "        covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n",
    "\n",
    "    \n",
    "    if np.iscomplexobj(covmean):\n",
    "        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
    "            m = np.max(np.abs(covmean.imag))\n",
    "            raise ValueError('Imaginary component {}'.format(m))\n",
    "        covmean = covmean.real\n",
    "\n",
    "    tr_covmean = np.trace(covmean)\n",
    "\n",
    "    return (diff.dot(diff) + np.trace(sigma1) +\n",
    "            np.trace(sigma2) - 2 * tr_covmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate frechet inception distance\n",
    "def calculate_fid(model, images1, images2):\n",
    "\t# calculate activations\n",
    "\twith torch.no_grad():\n",
    "\t\tact1 = model(images1).cpu().detach().numpy()\n",
    "\t\tact2 = model(images2).cpu().detach().numpy()\n",
    "\t# calculate mean and covariance statistics\n",
    "\tmu1, sigma1 = np.mean(act1, axis=0), np.cov(act1, rowvar=False)\n",
    "\tmu2, sigma2 = np.mean(act2, axis=0), np.cov(act2, rowvar=False)\n",
    "\t\n",
    "\treturn calculate_frechet_distance(mu1, sigma1, mu2, sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(299),\n",
    "    transforms.CenterCrop(299),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Image.open('../test_images/flower1.jpg')\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch_1 = input_tensor.unsqueeze(0)\n",
    "\n",
    "input_image = Image.open('../test_images/flower2.jpg')\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch_2 = input_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID (same): 0.000\n",
      "FID (different): 889.460\n"
     ]
    }
   ],
   "source": [
    "# fid between images1 and images1\n",
    "fid = calculate_fid(model, input_batch_1, input_batch_1)\n",
    "print('FID (same): %.3f' % fid)\n",
    "# fid between images1 and images2\n",
    "fid = calculate_fid(model, input_batch_1, input_batch_2)\n",
    "print('FID (different): %.3f' % fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pytorch-FID Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pytorch_fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_fid import fid_score, inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "dim = 2048\n",
    "paths = []\n",
    "for name in dir_names:\n",
    "    path = tmp_path / name\n",
    "    path.mkdir()\n",
    "    paths.append(str(path))\n",
    "\n",
    "fid_value = fid_score.calculate_fid_given_paths(paths,\n",
    "    batch_size=dim,\n",
    "    device=device,\n",
    "    dims=dim,\n",
    "    num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Ignite Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pytorch-ignite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import scipy\n",
    "from torch import nn, optim\n",
    "\n",
    "from ignite.engine import *\n",
    "from ignite.handlers import *\n",
    "from ignite.metrics import *\n",
    "from ignite.utils import *\n",
    "from ignite.contrib.metrics.regression import *\n",
    "from ignite.contrib.metrics import *\n",
    "\n",
    "# create default evaluator for doctests\n",
    "\n",
    "def eval_step(engine, batch):\n",
    "    return batch\n",
    "\n",
    "default_evaluator = Engine(eval_step)\n",
    "\n",
    "# create default optimizer for doctests\n",
    "\n",
    "param_tensor = torch.zeros([1], requires_grad=True)\n",
    "default_optimizer = torch.optim.SGD([param_tensor], lr=0.1)\n",
    "\n",
    "# create default trainer for doctests\n",
    "# as handlers could be attached to the trainer,\n",
    "# each test must define his own trainer using `.. testsetup:`\n",
    "\n",
    "def get_default_trainer():\n",
    "\n",
    "    def train_step(engine, batch):\n",
    "        return batch\n",
    "\n",
    "    return Engine(train_step)\n",
    "\n",
    "# create default model for doctests\n",
    "\n",
    "default_model = nn.Sequential(OrderedDict([\n",
    "    ('base', nn.Linear(4, 2)),\n",
    "    ('fc', nn.Linear(2, 1))\n",
    "]))\n",
    "\n",
    "manual_seed(666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willf\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\linalg\\_matfuncs_sqrtm.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  arg2 = norm(X.dot(X) - A, 'fro')**2 / norm(A, 'fro')\n"
     ]
    }
   ],
   "source": [
    "metric = FID(num_features=1, feature_extractor=default_model)\n",
    "metric.attach(default_evaluator, \"fid\")\n",
    "y_true = torch.ones(10, 4)\n",
    "y_pred = torch.ones(10, 4)\n",
    "state = default_evaluator.run([[y_pred, y_true]])\n",
    "print(state.metrics[\"fid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "259771fb0e24a764efce4fd955c0b099f3a7b4b1af73db6068fac1ad6a526fe6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
